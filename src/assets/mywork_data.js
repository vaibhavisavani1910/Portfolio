import img1 from "../assets/img1.jpg";
import img2 from "../assets/img2.jpg";
import img3 from "../assets/img3.jpg";
import img4 from "../assets/img4.jpg";
import img5 from "../assets/img5.jpg";
import img6 from "../assets/img6.jpeg";
import img7 from "../assets/img7.jpg";


const mywork_data = [
  {
    w_no: 1,
    w_name: "RedResearch - Reddit AI Agent",
    w_img: img1,
    w_desc:
      "An intelligent Reddit assistant that lets you search any topic, fetch top threads, and summarize discussions with AI-powered insights â€” all through a sleek conversational interface.",
    w_tags: [
      "Python",
      "Flask",
      "LLM",
      "OpenAI API",
      "Web Scraping",
      "Streamlit",
      "Prompt Engineering"
    ],
    w_link: "https://github.com/vaibhavisavani1910/RedResearch",
  },
  {
    w_no: 2,
    w_name: "ðŸ§  Candidate Recommendation Engine",
    w_img: img2,
    w_desc:
      "A smart engine that ranks candidate resumes by relevance to a job description using vector embeddings, semantic search, and LLM-based evaluation. Built with Gradio UI and deployed on Hugging Face Spaces.",
    w_tags: [
      "Python",
      "Gradio",
      "OpenAI API",
      "Gemini",
      "MongoDB Atlas",
      "LangChain",
      "Vector Search",
      "Hugging Face"
    ],
    w_link: "https://github.com/vaibhavisavani1910/Candidate-Recommendation",
  },
  {
    w_no: 3,
    w_name: "ðŸš€ EngineeringCrew",
    w_img: img3,
    w_desc:
      "An AI-powered software engineering team built with CrewAI to autonomously design, develop, and test software solutions through specialized multi-agent collaboration.",
    w_tags: [
      "Python",
      "CrewAI",
      "YAML",
      "Docker",
      "Autonomous Agents",
      "AI Engineering"
    ],
    w_link: "https://github.com/vaibhavisavani1910/CrewAI/tree/main/engineering_crew",
  },{
    w_no: 4,
    w_name: "AI-Powered Stock Trading Crew (CrewAI)",
    w_img: img4,
    w_desc:
      "An AI-native multi-agent system built with CrewAI that autonomously discovers trending companies, performs financial research, and recommends top stock picks using memory-enhanced reasoning with LTM and STM modules.",
    w_tags: [
      "Python",
      "CrewAI",
      "OpenAI Embeddings",
      "SQLite",
      "Serper.dev",
      "Push Notifications",
      "Long-Term Memory (LTM)",
      "Short-Term Memory (STM)"
    ],
    w_link: "https://github.com/vaibhavisavani1910/CrewAI/tree/main/best_trading_agent",
  },  
  {
    
      w_no: 5,
      w_name: "Project Tracker",
      w_img: img5,
      w_desc:
        "A full-stack task management app built with Angular, Flask, and MongoDB to track tasks across multiple projects. Deployed on AWS with a load balancer for scalable performance.",
      w_tags: [
        "Angular",
        "Flask",
        "MongoDB",
        "AWS",
        "Load Balancing",
        "Full-Stack"
      ],
      w_link: "https://github.com/vaibhavisavani1910/Project-Traker",
  
  },
  {
    w_no: 6,
    w_name: "RAG Models Playground",
    w_img: img6,
    w_desc:
      "An interactive exploration of Retrieval-Augmented Generation (RAG) techniques using LangChain, MongoDB Atlas, and OpenAI embeddings. Includes experiments like re-ranking, semantic chunking, HyDE, multi-modal captioning, and GraphRAG.",
    w_tags: [
      "Python",
      "LangChain",
      "OpenAI API",
      "MongoDB Atlas",
      "RAG",
      "LLMs",
      "Vector Search",
      "GraphRAG"
    ],
    w_link: "https://github.com/vaibhavisavani1910/Advanced-RAG",
  },
  {
    w_no: 7,
    w_name: "Smart Symptom and Triage Assistant",
    w_img: img7,
    w_desc:
      "An AI-powered medical assistant that predicts diseases based on symptoms using a fine-tuned LLM enhanced with Retrieval-Augmented Generation (RAG) for accurate and context-aware diagnosis.",
    w_tags: [
      "Python",
      "LangChain",
      "RAG",
      "BioBERT",
      "MiniLM",
      "GPT-Neo",
      "Web Scraping",
      "Healthcare AI"
    ],
    w_link: "https://github.com/vaibhavisavani1910/diseases_prediction_RAG",
  }
];

export default mywork_data;
